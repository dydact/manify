{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# graphs_c[\"task\"] = graphs_c[\"embedding\"].map(graph_task_dict)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m graphs_c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 134\u001b[0m graphs_c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgraphs_c\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(graph_dataset_names)\n\u001b[1;32m    135\u001b[0m graphs_c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m graphs_r \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/results_icml_revision/regression_nn_graph.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Make table\n",
    "def process_table(table, groupby, task):\n",
    "    means = table.groupby(groupby).mean()\n",
    "    stderrs = table.groupby(groupby).sem()\n",
    "\n",
    "\n",
    "# # Single-signature Gaussians\n",
    "# def curv2sig(curv):\n",
    "#     if curv > 0:\n",
    "#         return \"$\\\\H{2,\" + str(curv) + \"}$\"\n",
    "#     elif curv < 0:\n",
    "#         return \"$\\\\S{2,\" + str(curv) + \"}$\"\n",
    "#     else:\n",
    "#         return \"$\\\\E{2}$\"\n",
    "\n",
    "# Multiple-signature Gaussians\n",
    "# sig_dict = {\n",
    "#     \"H\": \"$\\\\H{4}$\",\n",
    "#     \"E\": \"$\\\\E{4}$\",\n",
    "#     \"S\": \"$\\\\S{4}$\",\n",
    "#     \"HH\": \"($\\\\H{2})^2$\",\n",
    "#     \"HE\": \"$\\\\H{2}\\\\E{2}$\",\n",
    "#     \"HS\": \"$\\\\H{2}\\\\S{2}$\",\n",
    "#     \"SE\": \"$\\\\S{2}\\\\E{2}$\",\n",
    "#     \"SS\": \"$(\\\\S{2})^2$\",\n",
    "# }\n",
    "\n",
    "\n",
    "class_1man = pd.read_table(\"../data/results_icml_revision/classification_nn_single_curvature.tsv\")\n",
    "class_1man[\"task\"] = \"C\"\n",
    "# class_1man[\"signature\"] = class_1man[\"curvature\"].map(curv2sig)\n",
    "class_1man[\"dataset\"] = \"Gaussian\"\n",
    "\n",
    "reg_1man = pd.read_table(\"../data/results_icml_revision/regression_nn_single_curvature.tsv\")\n",
    "reg_1man[\"task\"] = \"R\"\n",
    "# reg_1man[\"signature\"] = reg_1man[\"curvature\"].map(curv2sig)\n",
    "reg_1man[\"dataset\"] = \"Gaussian\"\n",
    "\n",
    "\n",
    "\n",
    "class_sig = pd.read_table(\"../data/results_icml_revision/classification_nn_multiple_curvatures.tsv\")\n",
    "class_sig[\"task\"] = \"C\"\n",
    "# class_sig[\"signature\"] = class_sig[\"signature\"].map(sig_dict)\n",
    "class_sig[\"dataset\"] = \"Gaussian\"\n",
    "\n",
    "reg_sig = pd.read_table(\"../data/results_icml_revision/regression_nn_multiple_curvatures.tsv\")\n",
    "reg_sig[\"task\"] = \"R\"\n",
    "# reg_sig[\"signature\"] = reg_sig[\"signature\"].map(sig_dict)\n",
    "reg_sig[\"dataset\"] = \"Gaussian\"\n",
    "\n",
    "# Empirical datasets\n",
    "# temp = pd.read_table(\"../data/results_icml/temperature.tsv\")\n",
    "# temp[\"task\"] = \"R\"\n",
    "# temp[\"signature\"] = \"$\\\\S{2}\\\\S{1}$\"\n",
    "# temp[\"dataset\"] = \"Temperature\"\n",
    "\n",
    "# fourier = pd.read_table(\"../data/results_icml/fourier.tsv\")\n",
    "# fourier[\"task\"] = \"C\"\n",
    "# fourier[\"signature\"] = \"$(\\\\S{1})^5$\"\n",
    "# fourier[\"dataset\"] = \"Neuron 33\"\n",
    "\n",
    "# fourier2 = pd.read_table(\"../data/results_icml/fourier2.tsv\")\n",
    "# fourier2[\"task\"] = \"C\"\n",
    "# fourier2[\"signature\"] = \"$(\\\\S{1})^5$\"\n",
    "# fourier2[\"dataset\"] = \"Neuron 46\"\n",
    "\n",
    "# traffic = pd.read_table(\"../data/results_icml/traffic_results.tsv\")\n",
    "# traffic[\"task\"] = \"R\"\n",
    "# traffic[\"signature\"] = \"$\\\\E{1}(\\\\S{1})^4$\"\n",
    "# traffic[\"dataset\"] = \"Traffic\"\n",
    "\n",
    "# land_water = pd.read_table(\"../data/results_icml/land_vs_water.tsv\")\n",
    "# land_water[\"task\"] = \"C\"\n",
    "# land_water[\"signature\"] = \"$\\\\S{2}$\"\n",
    "# land_water[\"dataset\"] = \"Landmasses\"\n",
    "\n",
    "# empirical = pd.read_table(\"../data/results_icml_revision/all_nn_empirical.tsv\")\n",
    "# empirical[\"table\"] = \"Other\"\n",
    "# empirical_c = empirical[empirical[\"dataset\"].isin([\"landmasses\", \"neuron_33\", \"neuron_46\"])]\n",
    "# empirical_c[\"task\"] = \"C\"\n",
    "# empirical_r = empirical[empirical[\"dataset\"].isin([\"temperature\", \"traffic\"])]\n",
    "# empirical_r[\"task\"] = \"R\"\n",
    "# Put in signatures\n",
    "# empirical_sigdict = {\n",
    "#     \"landmasses\": \"$\\\\S{2}$\",\n",
    "#     \"neuron_33\": \"$(\\\\S{1})^{10}$\",\n",
    "#     \"neuron_46\": \"$(\\\\S{1})^{10}$\",\n",
    "#     \"temperature\": \"$\\\\S{2}\\\\S{1}$\",\n",
    "#     \"traffic\": \"$\\\\E{1}(\\\\S{1})^4$\",\n",
    "# }\n",
    "# empirical_c[\"signature\"] = empirical_c[\"dataset\"].map(empirical_sigdict)\n",
    "# empirical_r[\"signature\"] = empirical_r[\"dataset\"].map(empirical_sigdict)\n",
    "# empirical_namedict = {\n",
    "#     \"landmasses\": \"Landmasses\",\n",
    "#     \"neuron_33\": \"Neuron 33\",\n",
    "#     \"neuron_46\": \"Neuron 46\",\n",
    "#     \"temperature\": \"Temperature\",\n",
    "#     \"traffic\": \"Traffic\",\n",
    "# }\n",
    "# empirical_c[\"dataset\"] = empirical_c[\"dataset\"].map(empirical_namedict)\n",
    "# empirical_r[\"dataset\"] = empirical_r[\"dataset\"].map(empirical_namedict)\n",
    "\n",
    "# Graph datasets - only keep lowest d_avg\n",
    "# graph_task_dict = {\n",
    "#     \"polblogs\": \"C\",\n",
    "#     \"citeseer\": \"C\",\n",
    "#     \"cora\": \"C\",\n",
    "#     \"cs_phds\": \"R\",\n",
    "# }\n",
    "graph_dataset_names = {\n",
    "    \"polblogs\": \"PolBlogs\",\n",
    "    \"citeseer\": \"CiteSeer\",\n",
    "    \"cora\": \"Cora\",\n",
    "    \"cs_phds\": \"CS PhDs\",\n",
    "}\n",
    "graphs_c = pd.read_table(\"../data/results_icml_revision/classification_nn_graph.tsv\")\n",
    "# graphs = graphs.groupby([\"embedding\", \"signature\"]).mean().sort_values(\"d_avg\").reset_index().groupby(\"embedding\").first().reset_index()\n",
    "# best_sigs = (\n",
    "#     graphs.groupby([\"embedding\", \"signature\"])\n",
    "#     .mean()\n",
    "#     .sort_values(\"d_avg\")\n",
    "#     .reset_index()\n",
    "#     .groupby(\"embedding\")\n",
    "#     .first()\n",
    "#     .reset_index()[[\"embedding\", \"signature\"]]\n",
    "# )\n",
    "# graphs = pd.merge(graphs, best_sigs, on=[\"embedding\", \"signature\"])\n",
    "graphs_c[\"signature\"] = graphs_c[\"signature\"].map(sig_dict)\n",
    "# graphs_c[\"task\"] = graphs_c[\"embedding\"].map(graph_task_dict)\n",
    "graphs_c[\"task\"] = \"C\"\n",
    "graphs_c[\"dataset\"] = graphs_c[\"embedding\"].map(graph_dataset_names)\n",
    "graphs_c[\"table\"] = \"Graphs\"\n",
    "\n",
    "graphs_r = pd.read_table(\"../data/results_icml_revision/regression_nn_graph.tsv\")\n",
    "graphs_r[\"signature\"] = graphs_r[\"signature\"].map(sig_dict)\n",
    "# graphs_r[\"task\"] = graphs_r[\"embedding\"].map(graph_task_dict)\n",
    "graphs_r[\"task\"] = \"R\"\n",
    "graphs_r[\"dataset\"] = graphs_r[\"embedding\"].map(graph_dataset_names)\n",
    "graphs_r[\"table\"] = \"Graphs\"\n",
    "\n",
    "graphs = pd.concat([graphs_c, graphs_r])\n",
    "\n",
    "# # Link prediction datasets\n",
    "# link_dataset_names = {\n",
    "#     \"football\": \"Football\",\n",
    "#     \"karate_club\": \"Karate Club\",\n",
    "#     \"polbooks\": \"PolBooks\",\n",
    "#     \"adjnoun\": \"AdjNoun\",\n",
    "#     \"dolphins\": \"Dolphins\",\n",
    "#     \"lesmis\": \"Les Mis\",\n",
    "# }\n",
    "# links = pd.read_table(\"../data/results_icml_revision/link_prediction.tsv\")\n",
    "# links[\"task\"] = \"LP\"\n",
    "# # links[\"signature\"] = \"$(\\\\S{2}\\\\E{2}\\\\H{2})^2\\\\E{1}$\"\n",
    "# links[\"signature\"] = \"$\\\\S{2}\\\\E{2}\\\\H{2}$\"\n",
    "# links[\"dataset\"] = links[\"dataset\"].map(link_dataset_names)\n",
    "\n",
    "# VAE dataset\n",
    "vae_signature_dict = {\n",
    "    \"blood_cell_scrna\": \"$\\\\S{2}\\\\E{2}(\\\\H{2})^3$\",\n",
    "    \"lymphoma\": \"$(\\\\S{2})^2$\",\n",
    "    \"cifar_100\": \"$(\\\\S{2})^4$\",\n",
    "    \"mnist\": \"$\\\\S{2}\\\\E{2}\\\\H{2}$\",\n",
    "}\n",
    "vae_dataset_names = {\n",
    "    \"blood_cell_scrna\": \"Blood\",\n",
    "    \"lymphoma\": \"Lymphoma\",\n",
    "    \"cifar_100\": \"CIFAR-100\",\n",
    "    \"mnist\": \"MNIST\",\n",
    "}\n",
    "# vae = pd.read_table(\"../data/results_icml_revision/vae.tsv\")\n",
    "# vae[\"task\"] = \"C\"\n",
    "# vae[\"signature\"] = vae[\"embedding\"].map(vae_signature_dict)\n",
    "# vae[\"dataset\"] = vae[\"embedding\"].map(vae_dataset_names)\n",
    "\n",
    "# Put it all together\n",
    "class_1man[\"table\"] = \"Synthetic (single $K$)\"\n",
    "reg_1man[\"table\"] = \"Synthetic (single $K$)\"\n",
    "class_sig[\"table\"] = \"Synthetic (multi-$K$)\"\n",
    "reg_sig[\"table\"] = \"Synthetic (multi-$K$)\"\n",
    "# temp[\"table\"] = \"Other\"\n",
    "# fourier[\"table\"] = \"Other\"\n",
    "# fourier2[\"table\"] = \"Other\"\n",
    "# traffic[\"table\"] = \"Other\"\n",
    "# land_water[\"table\"] = \"Other\"\n",
    "graphs[\"table\"] = \"Graph embeddings\"\n",
    "# links[\"table\"] = \"Graph embeddings\"\n",
    "vae[\"table\"] = \"VAE\"\n",
    "\n",
    "all_data = pd.concat(\n",
    "    [\n",
    "        class_1man,\n",
    "        reg_1man,\n",
    "        class_sig,\n",
    "        reg_sig,\n",
    "        # temp,\n",
    "        # fourier,\n",
    "        # fourier2,\n",
    "        # traffic,\n",
    "        # land_water,\n",
    "        graphs,\n",
    "        # links,\n",
    "        vae,\n",
    "    ]\n",
    ")\n",
    "# all_data = all_data.drop(columns=[\"embedding\", \"curvature\", \"d_avg\", \"seed\", \"trial\"])\n",
    "all_data = all_data.drop(columns=[\"embedding\", \"curvature\", \"seed\", \"trial\"])\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../data/results_icml/all_results.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_table(\"../data/results_icml/all_results.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'product_dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'product_dt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Calculate mean and SE for each predictor\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m group1 \u001b[38;5;241m+\u001b[39m group2:\n\u001b[0;32m---> 98\u001b[0m     mean, se, n \u001b[38;5;241m=\u001b[39m mean_se(\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     99\u001b[0m     group_results[pred] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mse\u001b[39m\u001b[38;5;124m\"\u001b[39m: se}\n\u001b[1;32m    100\u001b[0m     n_samples[pred] \u001b[38;5;241m=\u001b[39m n\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'product_dt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import pandas as pd\n",
    "\n",
    "USE_BONFERRONI = True\n",
    "P_VAL = 0.05\n",
    "ADJUSTMENT = 10 if USE_BONFERRONI else 1  # 5 choose 2\n",
    "\n",
    "\n",
    "# Function to calculate mean and standard error\n",
    "def mean_se(series):\n",
    "    return series.mean(), series.sem(), series.count()\n",
    "\n",
    "\n",
    "# Define predictors to compare\n",
    "group1 = [\"product_dt\", \"sklearn_dt\", \"tangent_dt\", \"knn\", \"ps_perceptron\"]\n",
    "group2 = [\"product_rf\", \"sklearn_rf\", \"tangent_rf\", \"knn\", \"ps_perceptron\"]\n",
    "\n",
    "# Initialize LaTeX symbols for Wilcoxon test results\n",
    "latex_symbols = {\n",
    "    \"product_dt\": \"\\col{product_dt}{*}\",\n",
    "    \"product_rf\": \"\\col{product_dt}{*}\",\n",
    "    \"sklearn_dt\": \"\\col{euclidean_dt}{†}\",\n",
    "    \"sklearn_rf\": \"\\col{euclidean_dt}{†}\",\n",
    "    \"tangent_dt\": \"\\col{tangent_dt}{‡}\",\n",
    "    \"tangent_rf\": \"\\col{tangent_dt}{‡}\",\n",
    "    \"knn\": \"\\col{knn}{§}\",\n",
    "    \"ps_perceptron\": \"\\col{perceptron}{¶}\",\n",
    "}\n",
    "\n",
    "\n",
    "# Function to format a LaTeX cell with mean ± SE and symbols\n",
    "def format_latex_cell(mean, se, bold=False, underline=False, symbols=None, regression=False):\n",
    "    if regression:\n",
    "        # formatted = f\"{mean:.3f}\".lstrip(\"0\") + \" \\scriptsize ± \" + f\"{se:.3f}\".lstrip(\"0\")\n",
    "        formatted = f\"{mean:.3f}\".lstrip(\"0\") + \" ± \" + f\"{se:.3f}\".lstrip(\"0\")\n",
    "    else:\n",
    "        # formatted = f\"{mean * 100:.1f}\".lstrip(\"0\") + \"\\scriptsize ± \" + f\"{se * 100:.1f}\".lstrip(\"0\")\n",
    "        formatted = f\"{mean * 100:.1f}\".lstrip(\"0\") + \" ± \" + f\"{se * 100:.1f}\".lstrip(\"0\")\n",
    "    if bold:\n",
    "        formatted = f\"\\\\textbf{{{formatted}}}\"\n",
    "    if underline:\n",
    "        formatted = f\"\\\\underline{{{formatted}}}\"\n",
    "    if symbols:\n",
    "        # Remove duplicates\n",
    "        symbols = sorted(list(set(symbols)))\n",
    "        formatted += f\"\\\\textsuperscript{{{''.join(symbols)}}}\"\n",
    "    return formatted\n",
    "\n",
    "\n",
    "# Function to run Wilcoxon test between predictors within group1 and within group2\n",
    "def run_wilcoxon_tests(group1_vals, group2_vals, regression=False):\n",
    "    symbols = {key: [] for key in group1 + group2}\n",
    "\n",
    "    # Compare all pairs within group1\n",
    "    for i, pred1 in enumerate(group1):\n",
    "        for pred2 in group1[i + 1 :]:\n",
    "            if group1_vals[pred1].isnull().all() or group1_vals[pred2].isnull().all():\n",
    "                continue\n",
    "            elif (not regression and group1_vals[pred1].mean() > group1_vals[pred2].mean()) or (\n",
    "                regression and group1_vals[pred1].mean() < group1_vals[pred2].mean()\n",
    "            ):\n",
    "                stat, p_value = wilcoxon(group1_vals[pred1], group1_vals[pred2])\n",
    "                if p_value < P_VAL / ADJUSTMENT:\n",
    "                    symbols[pred1].append(latex_symbols[pred2])\n",
    "                    symbols[pred2].append(latex_symbols[pred1])\n",
    "\n",
    "    # Compare all pairs within group2\n",
    "    for i, pred1 in enumerate(group2):\n",
    "        for pred2 in group2[i + 1 :]:\n",
    "            if group2_vals[pred1].isnull().all() or group2_vals[pred2].isnull().all():\n",
    "                continue\n",
    "            # elif group2_vals[pred1].mean() > group2_vals[pred2].mean():\n",
    "            elif (not regression and group2_vals[pred1].mean() > group2_vals[pred2].mean()) or (\n",
    "                regression and group2_vals[pred1].mean() < group2_vals[pred2].mean()\n",
    "            ):\n",
    "                stat, p_value = wilcoxon(group2_vals[pred1], group2_vals[pred2])\n",
    "                if p_value < P_VAL / ADJUSTMENT:\n",
    "                    symbols[pred1].append(latex_symbols[pred2])\n",
    "                    symbols[pred2].append(latex_symbols[pred1])\n",
    "\n",
    "    return symbols\n",
    "\n",
    "\n",
    "# Group by task and dataset\n",
    "# grouped = all_data.groupby([\"table\", \"task\", \"dataset\", \"signature\"])\n",
    "grouped = all_data.groupby([\"table\", \"dataset\", \"task\", \"signature\"])\n",
    "\n",
    "# Iterate through each group and process data\n",
    "results = {}\n",
    "# for (table, task, dataset, signature), group in grouped:\n",
    "for (table, dataset, task, signature), group in grouped:\n",
    "    group_results = {}\n",
    "    n_samples = {}\n",
    "\n",
    "    # Calculate mean and SE for each predictor\n",
    "    for pred in group1 + group2:\n",
    "        mean, se, n = mean_se(group[pred])\n",
    "        group_results[pred] = {\"mean\": mean, \"se\": se}\n",
    "        n_samples[pred] = n\n",
    "\n",
    "    # Run Wilcoxon tests and gather symbols\n",
    "    symbols = run_wilcoxon_tests(group[group1], group[group2], regression=(task == \"R\"))\n",
    "\n",
    "    # Bold the best predictor\n",
    "    if task == \"R\":\n",
    "        best_pred = min(group_results, key=lambda x: group_results[x][\"mean\"])\n",
    "        second_best_pred = sorted(group_results, key=lambda x: group_results[x][\"mean\"])[1]\n",
    "    else:  # LP and C\n",
    "        best_pred = max(group_results, key=lambda x: group_results[x][\"mean\"])\n",
    "        second_best_pred = sorted(group_results, key=lambda x: group_results[x][\"mean\"])[-2]\n",
    "\n",
    "    # Format the results for LaTeX\n",
    "    # latex_table = {\"$n$\": max(n_samples.values())}\n",
    "    latex_table = {}\n",
    "    for pred in group1 + group2:\n",
    "        bold = pred == best_pred\n",
    "        underline = pred == second_best_pred\n",
    "        latex_table[pred] = format_latex_cell(\n",
    "            group_results[pred][\"mean\"],\n",
    "            group_results[pred][\"se\"],\n",
    "            bold=bold,\n",
    "            underline=underline,\n",
    "            symbols=symbols.get(pred, []),\n",
    "            regression=(task == \"R\"),\n",
    "        )\n",
    "\n",
    "    # results[(table, task, dataset, signature)] = latex_table\n",
    "    results[(table, dataset, task, signature)] = latex_table\n",
    "\n",
    "# Convert results into a dataframe for display\n",
    "latex_df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "latex_df.columns = [\n",
    "    # \"$n$\",\n",
    "    \"\\col{product_dt}{Product DT}\",\n",
    "    \"\\col{euclidean_dt}{Euclidean DT}\",\n",
    "    \"\\col{tangent_dt}{Tangent DT}\",\n",
    "    \"\\col{knn}{$k$-Neighbors}\",\n",
    "    \"\\col{perceptron}{PS Perceptron}\",\n",
    "    \"\\col{product_dt}{Product RF}\",\n",
    "    \"\\col{euclidean_dt}{Euclidean RF}\",\n",
    "    \"\\col{tangent_dt}{Tangent RF}\",\n",
    "]\n",
    "\n",
    "# How I want it sorted\n",
    "sort_order_l1 = [\n",
    "    \"Synthetic (single $K$)\",\n",
    "    \"Synthetic (multi-$K$)\",\n",
    "    # \"Empirical\",\n",
    "    \"Graph embeddings\",\n",
    "    # \"VAE embeddings\",\n",
    "    # \"Graph\",\n",
    "    \"VAE\",\n",
    "    \"Other\",\n",
    "]\n",
    "sort_order_l2 = [\"C\", \"R\", \"LP\"]\n",
    "sort_order_l3 = [\n",
    "    \"Gaussian mixture\",\n",
    "    \"Global temperature\",\n",
    "    \"Neural spiking\",\n",
    "    \"PolBlogs\",\n",
    "    \"CiteSeer\",\n",
    "    \"Cora\",\n",
    "    \"CS PhDs\",\n",
    "    \"Football\",\n",
    "    \"Karate Club\",\n",
    "    \"PolBooks\",\n",
    "    \"AdjNoun\",\n",
    "    \"Blood\",\n",
    "    \"Lymphoma\",\n",
    "    \"CIFAR-100\",\n",
    "    \"MNIST\",\n",
    "    \"Traffic\",\n",
    "]\n",
    "sort_order_l3 = [sig_dict[sig] for sig in sig_dict]\n",
    "\n",
    "# Make dicts\n",
    "sort_dict1 = {name: i for i, name in enumerate(sort_order_l1)}\n",
    "sort_dict2 = {name: i for i, name in enumerate(sort_order_l2)}\n",
    "sort_dict3 = {name: i for i, name in enumerate(sort_order_l3)}\n",
    "\n",
    "latex_df = (\n",
    "    latex_df.assign(\n",
    "        sort1=latex_df.index.get_level_values(0).map(sort_dict1),\n",
    "        # sort2=latex_df.index.get_level_values(1).map(sort_dict2),\n",
    "        sort2=latex_df.index.get_level_values(1).map(sort_dict3),\n",
    "        # sort3=latex_df.index.get_level_values(2).map(sort_dict3),\n",
    "        sort3=latex_df.index.get_level_values(2).map(sort_dict2),\n",
    "    )\n",
    "    .sort_values([\"sort1\", \"sort2\", \"sort3\"])\n",
    "    .drop(columns=[\"sort1\", \"sort2\", \"sort3\"])\n",
    ")\n",
    "\n",
    "# Rotate index labels 1 and 2; add spacing for better alignment\n",
    "c_dict = {\n",
    "    \"Synthetic (single $K$)\": \"-5.5cm\",\n",
    "    \"Synthetic (multi-$K$)\": \"-4.5cm\",\n",
    "    \"Graph embeddings\": \"-3cm\",\n",
    "    \"VAE\": \"-1cm\",\n",
    "    \"Other\": \"-1cm\",\n",
    "}\n",
    "latex_df.index = pd.MultiIndex.from_tuples(\n",
    "    # [(f\"\\\\rotatebox{{-90}}{{{c}}}\", f\"\\\\rotatebox{{-90}}{{{t}}}\", d, s) for c, t, d, s in latex_df.index],\n",
    "    [(f\"\\\\rotatebox{{90}}{{\\\\hspace{{{c_dict[c]}}}{c}}}\", t, d, s) for c, t, d, s in latex_df.index],\n",
    "    # names=[\"\", \"Task\", \"Dataset\", \"Signature\"],\n",
    "    names=[\"\", \"Dataset\", \"Task\", \"Signature\"],\n",
    ")\n",
    "\n",
    "# Drop columns that never win; rearrange to suit our needs\n",
    "# latex_df = latex_df.drop(\n",
    "# columns=[\"\\col{tangent_dt}{Tangent DT}\", \"\\col{perceptron}{PS Perceptron}\", \"\\col{tangent_dt}{Tangent RF}\"]\n",
    "# )\n",
    "latex_df = latex_df[\n",
    "    [\n",
    "        \"\\col{perceptron}{PS Perceptron}\",\n",
    "        \"\\col{knn}{$k$-Neighbors}\",\n",
    "        \"\\col{euclidean_dt}{Euclidean DT}\",\n",
    "        \"\\col{euclidean_dt}{Euclidean RF}\",\n",
    "        \"\\col{tangent_dt}{Tangent DT}\",\n",
    "        \"\\col{tangent_dt}{Tangent RF}\",\n",
    "        \"\\col{product_dt}{Product DT}\",\n",
    "        \"\\col{product_dt}{Product RF}\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "latex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = latex_df.to_latex(\n",
    "    # \"../data/results/latex_table.tex\",\n",
    "    escape=False,\n",
    "    # column_format=\"|>{\\centering\\\\arraybackslash}p{2cm}|>{\\centering\\\\arraybackslash}p{2cm}|p{2cm}|p{2cm}|\",\n",
    "    # column_format=\">{\\centering\\\\arraybackslash}p{2cm}>{\\centering\\\\arraybackslash}p{2cm}p{2cm}p{2cm}rrrrrrrrr\",\n",
    "    # column_format=\">{\\centering\\\\arraybackslash}p{1cm}>{\\centering\\\\arraybackslash}p{1cm}p{1.5cm}p{1.5cm}llllllll\",\n",
    "    header=True,\n",
    ")\n",
    "\n",
    "# Remove all occurrences of \"\\cline{3-9}\"\n",
    "latex = latex.replace(\"\\\\cline{3-9}\", \"\")\n",
    "latex = latex.replace(\"\\\\cline{2-9}\", \"\")\n",
    "\n",
    "# Change top bar\n",
    "my_toprule = \"\"\"\\\\toprule\n",
    "& Dataset & Task & Signature & \\col{knn}{$k$-Neighbors} & \\col{euclidean_dt}{Euclidean \\\\ DT} & \\col{euclidean_dt}{Euclidean RF} & \\col{product_dt}{Product DT} & \\col{product_dt}{Product RF} \\\\\\\\\n",
    "\\midrule\"\"\"\n",
    "latex = latex.split(\"\\n\")\n",
    "latex = [latex[0], my_toprule] + latex[5:-4] + latex[-3:]\n",
    "latex = \"\\n\".join(latex)\n",
    "\n",
    "with open(\"../data/results/latex_table.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "knn           22\n",
       "product_rf    16\n",
       "sklearn_dt    10\n",
       "product_dt     3\n",
       "tangent_dt     3\n",
       "sklearn_rf     2\n",
       "tangent_rf     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often are we the max?\n",
    "\n",
    "all_data.groupby([\"table\", \"task\", \"dataset\", \"signature\"]).mean().idxmax(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_rf    30\n",
      "knn           13\n",
      "sklearn_rf     7\n",
      "sklearn_dt     4\n",
      "product_dt     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "product_rf       16\n",
      "tangent_rf       14\n",
      "sklearn_rf       12\n",
      "knn               6\n",
      "sklearn_dt        6\n",
      "product_dt        1\n",
      "ps_perceptron     1\n",
      "tangent_dt        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "True     52\n",
      "False     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "alldata_grouped = all_data.groupby([\"table\", \"task\", \"dataset\", \"signature\"]).mean()\n",
    "\n",
    "# Flip the sign for regression tasks\n",
    "alldata_grouped.loc[alldata_grouped.index.get_level_values(\"task\") == \"R\"] = -alldata_grouped.loc[\n",
    "    alldata_grouped.index.get_level_values(\"task\") == \"R\"\n",
    "]\n",
    "\n",
    "# How often are we the max?\n",
    "print(alldata_grouped.idxmax(axis=1).value_counts())\n",
    "print()\n",
    "\n",
    "# What about second best?\n",
    "print(alldata_grouped.apply(lambda x: x.nlargest(2).idxmin(), axis=1).value_counts())\n",
    "print()\n",
    "\n",
    "# How often is at least one of our predictors in the top 2?\n",
    "\n",
    "# Then, apply the check for top 2 scores in those columns\n",
    "result = alldata_grouped.apply(\n",
    "    lambda x: any(col in x.nlargest(2).index for col in [\"product_dt\", \"product_rf\"]), axis=1\n",
    ")\n",
    "# Print the counts of True/False values\n",
    "print(result.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICML smaller tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn_dt_f1-micro</th>\n",
       "      <th>sklearn_dt_accuracy</th>\n",
       "      <th>sklearn_dt_time</th>\n",
       "      <th>sklearn_rf_f1-micro</th>\n",
       "      <th>sklearn_rf_accuracy</th>\n",
       "      <th>sklearn_rf_time</th>\n",
       "      <th>product_dt_f1-micro</th>\n",
       "      <th>product_dt_accuracy</th>\n",
       "      <th>product_dt_time</th>\n",
       "      <th>product_rf_f1-micro</th>\n",
       "      <th>...</th>\n",
       "      <th>sklearn_rf_rmse</th>\n",
       "      <th>product_dt_rmse</th>\n",
       "      <th>product_rf_rmse</th>\n",
       "      <th>tangent_dt_rmse</th>\n",
       "      <th>tangent_rf_rmse</th>\n",
       "      <th>knn_rmse</th>\n",
       "      <th>ambient_mlp_rmse</th>\n",
       "      <th>ambient_gnn_rmse</th>\n",
       "      <th>kappa_gcn_rmse</th>\n",
       "      <th>product_mlr_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.154843</td>\n",
       "      <td>0.330</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.335</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.040652</td>\n",
       "      <td>0.420</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.027568</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.041864</td>\n",
       "      <td>0.400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.355</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.028096</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.041369</td>\n",
       "      <td>0.335</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.615</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.034132</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.030449</td>\n",
       "      <td>0.670</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.660</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.555</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.034312</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.028562</td>\n",
       "      <td>0.600</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.615</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.034523</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.030287</td>\n",
       "      <td>0.620</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.034249</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.029064</td>\n",
       "      <td>0.620</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sklearn_dt_f1-micro  sklearn_dt_accuracy  sklearn_dt_time  \\\n",
       "0                 0.395                0.395         0.005405   \n",
       "1                 0.335                0.335         0.002801   \n",
       "2                 0.370                0.370         0.002731   \n",
       "3                 0.380                0.380         0.002877   \n",
       "4                 0.355                0.355         0.002754   \n",
       "..                  ...                  ...              ...   \n",
       "25                0.615                0.615         0.004224   \n",
       "26                0.655                0.655         0.004258   \n",
       "27                0.555                0.555         0.004294   \n",
       "28                0.615                0.615         0.004275   \n",
       "29                0.610                0.610         0.004284   \n",
       "\n",
       "    sklearn_rf_f1-micro  sklearn_rf_accuracy  sklearn_rf_time  \\\n",
       "0                 0.385                0.385         0.027884   \n",
       "1                 0.375                0.375         0.026484   \n",
       "2                 0.360                0.360         0.027568   \n",
       "3                 0.420                0.420         0.026812   \n",
       "4                 0.360                0.360         0.028096   \n",
       "..                  ...                  ...              ...   \n",
       "25                0.650                0.650         0.034132   \n",
       "26                0.625                0.625         0.035156   \n",
       "27                0.575                0.575         0.034312   \n",
       "28                0.670                0.670         0.034523   \n",
       "29                0.630                0.630         0.034249   \n",
       "\n",
       "    product_dt_f1-micro  product_dt_accuracy  product_dt_time  \\\n",
       "0                 0.350                0.350         0.154843   \n",
       "1                 0.370                0.370         0.040652   \n",
       "2                 0.365                0.365         0.041864   \n",
       "3                 0.370                0.370         0.034583   \n",
       "4                 0.340                0.340         0.041369   \n",
       "..                  ...                  ...              ...   \n",
       "25                0.630                0.630         0.030449   \n",
       "26                0.635                0.635         0.030719   \n",
       "27                0.575                0.575         0.028562   \n",
       "28                0.580                0.580         0.030287   \n",
       "29                0.590                0.590         0.029064   \n",
       "\n",
       "    product_rf_f1-micro  ...  sklearn_rf_rmse  product_dt_rmse  \\\n",
       "0                 0.330  ...              NaN              NaN   \n",
       "1                 0.420  ...              NaN              NaN   \n",
       "2                 0.400  ...              NaN              NaN   \n",
       "3                 0.405  ...              NaN              NaN   \n",
       "4                 0.335  ...              NaN              NaN   \n",
       "..                  ...  ...              ...              ...   \n",
       "25                0.670  ...              NaN              NaN   \n",
       "26                0.660  ...              NaN              NaN   \n",
       "27                0.600  ...              NaN              NaN   \n",
       "28                0.620  ...              NaN              NaN   \n",
       "29                0.620  ...              NaN              NaN   \n",
       "\n",
       "    product_rf_rmse  tangent_dt_rmse  tangent_rf_rmse  knn_rmse  \\\n",
       "0               NaN              NaN              NaN       NaN   \n",
       "1               NaN              NaN              NaN       NaN   \n",
       "2               NaN              NaN              NaN       NaN   \n",
       "3               NaN              NaN              NaN       NaN   \n",
       "4               NaN              NaN              NaN       NaN   \n",
       "..              ...              ...              ...       ...   \n",
       "25              NaN              NaN              NaN       NaN   \n",
       "26              NaN              NaN              NaN       NaN   \n",
       "27              NaN              NaN              NaN       NaN   \n",
       "28              NaN              NaN              NaN       NaN   \n",
       "29              NaN              NaN              NaN       NaN   \n",
       "\n",
       "    ambient_mlp_rmse  ambient_gnn_rmse  kappa_gcn_rmse  product_mlr_rmse  \n",
       "0                NaN               NaN             NaN               NaN  \n",
       "1                NaN               NaN             NaN               NaN  \n",
       "2                NaN               NaN             NaN               NaN  \n",
       "3                NaN               NaN             NaN               NaN  \n",
       "4                NaN               NaN             NaN               NaN  \n",
       "..               ...               ...             ...               ...  \n",
       "25               NaN               NaN             NaN               NaN  \n",
       "26               NaN               NaN             NaN               NaN  \n",
       "27               NaN               NaN             NaN               NaN  \n",
       "28               NaN               NaN             NaN               NaN  \n",
       "29               NaN               NaN             NaN               NaN  \n",
       "\n",
       "[180 rows x 50 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_c = pd.concat([class_sig, graphs_c, vae, empirical_c])\n",
    "all_c = all_c.drop(columns=[\"embedding\", \"seed\", \"trial\", \"task\"])\n",
    "# all_c = all_c[[c for c in all_c.columns if \"accuracy\" in c]]\n",
    "all_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sklearn_dt_accuracy</th>\n",
       "      <th>sklearn_rf_accuracy</th>\n",
       "      <th>product_dt_accuracy</th>\n",
       "      <th>product_rf_accuracy</th>\n",
       "      <th>tangent_dt_accuracy</th>\n",
       "      <th>tangent_rf_accuracy</th>\n",
       "      <th>knn_accuracy</th>\n",
       "      <th>ps_perceptron_accuracy</th>\n",
       "      <th>ambient_mlp_accuracy</th>\n",
       "      <th>ambient_gnn_accuracy</th>\n",
       "      <th>kappa_gcn_accuracy</th>\n",
       "      <th>product_mlr_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <th>dataset</th>\n",
       "      <th>signature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Graphs</th>\n",
       "      <th>CiteSeer</th>\n",
       "      <th>$\\H{4}$</th>\n",
       "      <td>\\underline{25.9 ± .8}</td>\n",
       "      <td>25.5 ± .8</td>\n",
       "      <td>25.6 ± .8</td>\n",
       "      <td>\\textbf{26.2 ± .7}</td>\n",
       "      <td>25.5 ± .6</td>\n",
       "      <td>\\underline{25.9 ± .7}</td>\n",
       "      <td>25.1 ± .5</td>\n",
       "      <td>14.0 ± .4</td>\n",
       "      <td>24.5 ± .7</td>\n",
       "      <td>24.3 ± .6</td>\n",
       "      <td>23.8 ± .5</td>\n",
       "      <td>25.2 ± .7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cora</th>\n",
       "      <th>$\\H{4}$</th>\n",
       "      <td>28.3 ± .6</td>\n",
       "      <td>29.7 ± .4</td>\n",
       "      <td>28.1 ± .4</td>\n",
       "      <td>29.2 ± .5</td>\n",
       "      <td>28.4 ± .5</td>\n",
       "      <td>29.3 ± .4</td>\n",
       "      <td>20.8 ± .4</td>\n",
       "      <td>16.4 ± .4</td>\n",
       "      <td>\\textbf{29.9 ± .5}</td>\n",
       "      <td>29.6 ± .5</td>\n",
       "      <td>29.7 ± .5</td>\n",
       "      <td>\\underline{29.8 ± .4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolBlogs</th>\n",
       "      <th>$\\H{4}$</th>\n",
       "      <td>92.7 ± .6</td>\n",
       "      <td>93.1 ± .5</td>\n",
       "      <td>\\underline{93.4 ± .4}</td>\n",
       "      <td>\\underline{93.4 ± .4}</td>\n",
       "      <td>92.7 ± .7</td>\n",
       "      <td>\\textbf{93.9 ± .6}</td>\n",
       "      <td>92.9 ± .4</td>\n",
       "      <td>48.2 ± .7</td>\n",
       "      <td>91.7 ± .4</td>\n",
       "      <td>92.2 ± .4</td>\n",
       "      <td>91.5 ± .7</td>\n",
       "      <td>89.8 ± 1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Other</th>\n",
       "      <th>Landmasses</th>\n",
       "      <th>$\\S{2}$</th>\n",
       "      <td>83.5 ± .7</td>\n",
       "      <td>85.9 ± .9</td>\n",
       "      <td>86.5 ± .7</td>\n",
       "      <td>\\underline{87.4 ± .9}</td>\n",
       "      <td>85.2 ± .7</td>\n",
       "      <td>84.6 ± .8</td>\n",
       "      <td>\\textbf{91.8 ± .6}</td>\n",
       "      <td>69.8 ± 1.0</td>\n",
       "      <td>69.9 ± .8</td>\n",
       "      <td>77.2 ± .7</td>\n",
       "      <td>71.4 ± 1.7</td>\n",
       "      <td>65.2 ± .9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuron 33</th>\n",
       "      <th>$(\\S{1})^{10}$</th>\n",
       "      <td>\\textbf{78.7 ± 1.3}</td>\n",
       "      <td>\\underline{78.6 ± 1.2}</td>\n",
       "      <td>76.7 ± 1.3</td>\n",
       "      <td>77.5 ± 1.4</td>\n",
       "      <td>76.9 ± 1.5</td>\n",
       "      <td>76.6 ± 1.6</td>\n",
       "      <td>50.8 ± 1.6</td>\n",
       "      <td>54.7 ± .9</td>\n",
       "      <td>46.1 ± 1.4</td>\n",
       "      <td>48.1 ± 1.6</td>\n",
       "      <td>48.9 ± 1.8</td>\n",
       "      <td>47.7 ± 1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuron 46</th>\n",
       "      <th>$(\\S{1})^{10}$</th>\n",
       "      <td>60.0 ± .9</td>\n",
       "      <td>\\underline{61.8 ± .9}</td>\n",
       "      <td>59.6 ± .9</td>\n",
       "      <td>\\textbf{62.0 ± 1.2}</td>\n",
       "      <td>60.8 ± 1.1</td>\n",
       "      <td>60.6 ± 1.1</td>\n",
       "      <td>49.0 ± 1.5</td>\n",
       "      <td>51.9 ± 1.0</td>\n",
       "      <td>48.1 ± 1.1</td>\n",
       "      <td>48.3 ± 1.0</td>\n",
       "      <td>48.0 ± 1.0</td>\n",
       "      <td>47.8 ± 1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Synthetic (multi-$K$)</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">Gaussian</th>\n",
       "      <th>$(\\S{2})^2$</th>\n",
       "      <td>32.8 ± 1.2</td>\n",
       "      <td>35.4 ± 1.5</td>\n",
       "      <td>33.2 ± 1.3</td>\n",
       "      <td>\\textbf{36.8 ± 1.2}</td>\n",
       "      <td>33.4 ± 1.4</td>\n",
       "      <td>35.7 ± 1.4</td>\n",
       "      <td>\\underline{36.6 ± 1.6}</td>\n",
       "      <td>25.1 ± 1.6</td>\n",
       "      <td>30.5 ± 1.4</td>\n",
       "      <td>24.7 ± 1.2</td>\n",
       "      <td>14.4 ± 2.5</td>\n",
       "      <td>13.4 ± 2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\E{4}$</th>\n",
       "      <td>34.0 ± 1.6</td>\n",
       "      <td>\\textbf{37.2 ± 1.8}</td>\n",
       "      <td>33.2 ± 1.7</td>\n",
       "      <td>36.9 ± 1.4</td>\n",
       "      <td>34.0 ± 1.6</td>\n",
       "      <td>\\textbf{37.2 ± 1.8}</td>\n",
       "      <td>36.6 ± 1.3</td>\n",
       "      <td>24.0 ± 2.6</td>\n",
       "      <td>30.6 ± 1.5</td>\n",
       "      <td>26.8 ± 2.1</td>\n",
       "      <td>26.3 ± 2.3</td>\n",
       "      <td>30.6 ± 1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\H{2}\\E{2}$</th>\n",
       "      <td>34.6 ± 1.5</td>\n",
       "      <td>38.6 ± 2.1</td>\n",
       "      <td>34.8 ± 2.0</td>\n",
       "      <td>\\textbf{41.2 ± 2.0}</td>\n",
       "      <td>38.0 ± 1.4</td>\n",
       "      <td>39.1 ± 1.8</td>\n",
       "      <td>\\underline{39.8 ± 2.3}</td>\n",
       "      <td>20.7 ± 2.5</td>\n",
       "      <td>32.2 ± 2.0</td>\n",
       "      <td>27.8 ± 1.5</td>\n",
       "      <td>25.2 ± 1.6</td>\n",
       "      <td>31.4 ± 2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\H{2}\\S{2}$</th>\n",
       "      <td>33.9 ± 1.4</td>\n",
       "      <td>\\underline{37.6 ± 2.0}</td>\n",
       "      <td>36.0 ± 1.7</td>\n",
       "      <td>\\underline{37.6 ± 1.7}</td>\n",
       "      <td>34.2 ± 1.5</td>\n",
       "      <td>37.1 ± 1.9</td>\n",
       "      <td>\\textbf{38.1 ± 2.5}</td>\n",
       "      <td>20.2 ± 1.8</td>\n",
       "      <td>32.0 ± 1.7</td>\n",
       "      <td>22.5 ± 1.3</td>\n",
       "      <td>14.8 ± 2.4</td>\n",
       "      <td>17.7 ± 2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\H{4}$</th>\n",
       "      <td>34.7 ± 2.4</td>\n",
       "      <td>39.2 ± 1.6</td>\n",
       "      <td>39.0 ± 1.8</td>\n",
       "      <td>\\underline{45.2 ± 2.3}</td>\n",
       "      <td>38.4 ± 2.4</td>\n",
       "      <td>41.4 ± 1.5</td>\n",
       "      <td>\\textbf{45.3 ± 1.6}</td>\n",
       "      <td>18.9 ± 2.6</td>\n",
       "      <td>33.5 ± 2.1</td>\n",
       "      <td>18.0 ± 2.8</td>\n",
       "      <td>25.0 ± 2.6</td>\n",
       "      <td>34.5 ± 2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\S{2}\\E{2}$</th>\n",
       "      <td>33.2 ± 1.2</td>\n",
       "      <td>36.6 ± .9</td>\n",
       "      <td>31.7 ± .5</td>\n",
       "      <td>\\underline{37.2 ± 1.3}</td>\n",
       "      <td>33.6 ± 1.3</td>\n",
       "      <td>\\textbf{37.3 ± 1.4}</td>\n",
       "      <td>35.9 ± 1.3</td>\n",
       "      <td>25.8 ± 2.1</td>\n",
       "      <td>29.7 ± 1.1</td>\n",
       "      <td>26.7 ± 1.2</td>\n",
       "      <td>22.0 ± 2.5</td>\n",
       "      <td>17.5 ± 2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\S{4}$</th>\n",
       "      <td>23.0 ± 1.8</td>\n",
       "      <td>24.9 ± .9</td>\n",
       "      <td>25.5 ± .9</td>\n",
       "      <td>\\underline{28.3 ± 1.1}</td>\n",
       "      <td>21.2 ± .9</td>\n",
       "      <td>25.8 ± 1.0</td>\n",
       "      <td>\\textbf{30.2 ± .8}</td>\n",
       "      <td>15.4 ± .8</td>\n",
       "      <td>19.9 ± 1.2</td>\n",
       "      <td>21.1 ± 1.5</td>\n",
       "      <td>17.4 ± .5</td>\n",
       "      <td>16.5 ± 1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>($\\H{2})^2$</th>\n",
       "      <td>36.0 ± 1.1</td>\n",
       "      <td>37.7 ± 1.0</td>\n",
       "      <td>35.6 ± 1.0</td>\n",
       "      <td>\\underline{39.6 ± 1.5}</td>\n",
       "      <td>36.7 ± 1.0</td>\n",
       "      <td>38.7 ± 1.2</td>\n",
       "      <td>\\textbf{40.5 ± 1.0}</td>\n",
       "      <td>15.8 ± .9</td>\n",
       "      <td>31.5 ± 1.9</td>\n",
       "      <td>22.5 ± 1.1</td>\n",
       "      <td>24.3 ± 1.7</td>\n",
       "      <td>29.8 ± 1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">VAE</th>\n",
       "      <th>Blood</th>\n",
       "      <th>$\\S{2}\\E{2}(\\H{2})^3$</th>\n",
       "      <td>16.9 ± .8</td>\n",
       "      <td>\\textbf{18.4 ± .8}</td>\n",
       "      <td>14.3 ± 1.2</td>\n",
       "      <td>16.0 ± 1.2</td>\n",
       "      <td>16.8 ± .7</td>\n",
       "      <td>\\underline{18.3 ± .7}</td>\n",
       "      <td>15.9 ± .6</td>\n",
       "      <td>2.6 ± .2</td>\n",
       "      <td>12.0 ± .4</td>\n",
       "      <td>12.0 ± .4</td>\n",
       "      <td>11.3 ± .4</td>\n",
       "      <td>11.2 ± .3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIFAR-100</th>\n",
       "      <th>$(\\S{2})^4$</th>\n",
       "      <td>9.3 ± .5</td>\n",
       "      <td>\\underline{10.4 ± .5}</td>\n",
       "      <td>9.7 ± .4</td>\n",
       "      <td>10.3 ± .6</td>\n",
       "      <td>9.2 ± .5</td>\n",
       "      <td>\\textbf{10.6 ± .6}</td>\n",
       "      <td>7.9 ± .5</td>\n",
       "      <td>5.5 ± .3</td>\n",
       "      <td>8.1 ± .4</td>\n",
       "      <td>5.5 ± .3</td>\n",
       "      <td>4.9 ± .3</td>\n",
       "      <td>5.4 ± .4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lymphoma</th>\n",
       "      <th>$(\\S{2})^2$</th>\n",
       "      <td>81.9 ± 1.3</td>\n",
       "      <td>82.4 ± 1.2</td>\n",
       "      <td>\\underline{84.5 ± 1.1}</td>\n",
       "      <td>\\textbf{84.8 ± 1.1}</td>\n",
       "      <td>81.2 ± 1.2</td>\n",
       "      <td>82.1 ± 1.2</td>\n",
       "      <td>78.5 ± 1.3</td>\n",
       "      <td>75.7 ± 2.6</td>\n",
       "      <td>78.4 ± .3</td>\n",
       "      <td>78.4 ± .3</td>\n",
       "      <td>73.0 ± 5.6</td>\n",
       "      <td>67.2 ± 7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNIST</th>\n",
       "      <th>$\\S{2}\\E{2}\\H{2}$</th>\n",
       "      <td>34.0 ± 2.7</td>\n",
       "      <td>\\underline{37.6 ± 3.2}</td>\n",
       "      <td>34.0 ± 2.8</td>\n",
       "      <td>35.1 ± 4.4</td>\n",
       "      <td>33.7 ± 2.3</td>\n",
       "      <td>\\textbf{38.8 ± 3.2}</td>\n",
       "      <td>35.0 ± 4.3</td>\n",
       "      <td>16.2 ± 3.4</td>\n",
       "      <td>35.2 ± 3.9</td>\n",
       "      <td>14.7 ± 1.7</td>\n",
       "      <td>11.3 ± 1.1</td>\n",
       "      <td>21.8 ± 3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          sklearn_dt_accuracy  \\\n",
       "table                 dataset    signature                                      \n",
       "Graphs                CiteSeer   $\\H{4}$                \\underline{25.9 ± .8}   \n",
       "                      Cora       $\\H{4}$                            28.3 ± .6   \n",
       "                      PolBlogs   $\\H{4}$                            92.7 ± .6   \n",
       "Other                 Landmasses $\\S{2}$                            83.5 ± .7   \n",
       "                      Neuron 33  $(\\S{1})^{10}$           \\textbf{78.7 ± 1.3}   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                     60.0 ± .9   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                       32.8 ± 1.2   \n",
       "                                 $\\E{4}$                           34.0 ± 1.6   \n",
       "                                 $\\H{2}\\E{2}$                      34.6 ± 1.5   \n",
       "                                 $\\H{2}\\S{2}$                      33.9 ± 1.4   \n",
       "                                 $\\H{4}$                           34.7 ± 2.4   \n",
       "                                 $\\S{2}\\E{2}$                      33.2 ± 1.2   \n",
       "                                 $\\S{4}$                           23.0 ± 1.8   \n",
       "                                 ($\\H{2})^2$                       36.0 ± 1.1   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$              16.9 ± .8   \n",
       "                      CIFAR-100  $(\\S{2})^4$                         9.3 ± .5   \n",
       "                      Lymphoma   $(\\S{2})^2$                       81.9 ± 1.3   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$                 34.0 ± 2.7   \n",
       "\n",
       "                                                           sklearn_rf_accuracy  \\\n",
       "table                 dataset    signature                                       \n",
       "Graphs                CiteSeer   $\\H{4}$                             25.5 ± .8   \n",
       "                      Cora       $\\H{4}$                             29.7 ± .4   \n",
       "                      PolBlogs   $\\H{4}$                             93.1 ± .5   \n",
       "Other                 Landmasses $\\S{2}$                             85.9 ± .9   \n",
       "                      Neuron 33  $(\\S{1})^{10}$         \\underline{78.6 ± 1.2}   \n",
       "                      Neuron 46  $(\\S{1})^{10}$          \\underline{61.8 ± .9}   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                        35.4 ± 1.5   \n",
       "                                 $\\E{4}$                   \\textbf{37.2 ± 1.8}   \n",
       "                                 $\\H{2}\\E{2}$                       38.6 ± 2.1   \n",
       "                                 $\\H{2}\\S{2}$           \\underline{37.6 ± 2.0}   \n",
       "                                 $\\H{4}$                            39.2 ± 1.6   \n",
       "                                 $\\S{2}\\E{2}$                        36.6 ± .9   \n",
       "                                 $\\S{4}$                             24.9 ± .9   \n",
       "                                 ($\\H{2})^2$                        37.7 ± 1.0   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$      \\textbf{18.4 ± .8}   \n",
       "                      CIFAR-100  $(\\S{2})^4$             \\underline{10.4 ± .5}   \n",
       "                      Lymphoma   $(\\S{2})^2$                        82.4 ± 1.2   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$      \\underline{37.6 ± 3.2}   \n",
       "\n",
       "                                                           product_dt_accuracy  \\\n",
       "table                 dataset    signature                                       \n",
       "Graphs                CiteSeer   $\\H{4}$                             25.6 ± .8   \n",
       "                      Cora       $\\H{4}$                             28.1 ± .4   \n",
       "                      PolBlogs   $\\H{4}$                 \\underline{93.4 ± .4}   \n",
       "Other                 Landmasses $\\S{2}$                             86.5 ± .7   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                     76.7 ± 1.3   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                      59.6 ± .9   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                        33.2 ± 1.3   \n",
       "                                 $\\E{4}$                            33.2 ± 1.7   \n",
       "                                 $\\H{2}\\E{2}$                       34.8 ± 2.0   \n",
       "                                 $\\H{2}\\S{2}$                       36.0 ± 1.7   \n",
       "                                 $\\H{4}$                            39.0 ± 1.8   \n",
       "                                 $\\S{2}\\E{2}$                        31.7 ± .5   \n",
       "                                 $\\S{4}$                             25.5 ± .9   \n",
       "                                 ($\\H{2})^2$                        35.6 ± 1.0   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$              14.3 ± 1.2   \n",
       "                      CIFAR-100  $(\\S{2})^4$                          9.7 ± .4   \n",
       "                      Lymphoma   $(\\S{2})^2$            \\underline{84.5 ± 1.1}   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$                  34.0 ± 2.8   \n",
       "\n",
       "                                                           product_rf_accuracy  \\\n",
       "table                 dataset    signature                                       \n",
       "Graphs                CiteSeer   $\\H{4}$                    \\textbf{26.2 ± .7}   \n",
       "                      Cora       $\\H{4}$                             29.2 ± .5   \n",
       "                      PolBlogs   $\\H{4}$                 \\underline{93.4 ± .4}   \n",
       "Other                 Landmasses $\\S{2}$                 \\underline{87.4 ± .9}   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                     77.5 ± 1.4   \n",
       "                      Neuron 46  $(\\S{1})^{10}$            \\textbf{62.0 ± 1.2}   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$               \\textbf{36.8 ± 1.2}   \n",
       "                                 $\\E{4}$                            36.9 ± 1.4   \n",
       "                                 $\\H{2}\\E{2}$              \\textbf{41.2 ± 2.0}   \n",
       "                                 $\\H{2}\\S{2}$           \\underline{37.6 ± 1.7}   \n",
       "                                 $\\H{4}$                \\underline{45.2 ± 2.3}   \n",
       "                                 $\\S{2}\\E{2}$           \\underline{37.2 ± 1.3}   \n",
       "                                 $\\S{4}$                \\underline{28.3 ± 1.1}   \n",
       "                                 ($\\H{2})^2$            \\underline{39.6 ± 1.5}   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$              16.0 ± 1.2   \n",
       "                      CIFAR-100  $(\\S{2})^4$                         10.3 ± .6   \n",
       "                      Lymphoma   $(\\S{2})^2$               \\textbf{84.8 ± 1.1}   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$                  35.1 ± 4.4   \n",
       "\n",
       "                                                       tangent_dt_accuracy  \\\n",
       "table                 dataset    signature                                   \n",
       "Graphs                CiteSeer   $\\H{4}$                         25.5 ± .6   \n",
       "                      Cora       $\\H{4}$                         28.4 ± .5   \n",
       "                      PolBlogs   $\\H{4}$                         92.7 ± .7   \n",
       "Other                 Landmasses $\\S{2}$                         85.2 ± .7   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                 76.9 ± 1.5   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                 60.8 ± 1.1   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                    33.4 ± 1.4   \n",
       "                                 $\\E{4}$                        34.0 ± 1.6   \n",
       "                                 $\\H{2}\\E{2}$                   38.0 ± 1.4   \n",
       "                                 $\\H{2}\\S{2}$                   34.2 ± 1.5   \n",
       "                                 $\\H{4}$                        38.4 ± 2.4   \n",
       "                                 $\\S{2}\\E{2}$                   33.6 ± 1.3   \n",
       "                                 $\\S{4}$                         21.2 ± .9   \n",
       "                                 ($\\H{2})^2$                    36.7 ± 1.0   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$           16.8 ± .7   \n",
       "                      CIFAR-100  $(\\S{2})^4$                      9.2 ± .5   \n",
       "                      Lymphoma   $(\\S{2})^2$                    81.2 ± 1.2   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$              33.7 ± 2.3   \n",
       "\n",
       "                                                          tangent_rf_accuracy  \\\n",
       "table                 dataset    signature                                      \n",
       "Graphs                CiteSeer   $\\H{4}$                \\underline{25.9 ± .7}   \n",
       "                      Cora       $\\H{4}$                            29.3 ± .4   \n",
       "                      PolBlogs   $\\H{4}$                   \\textbf{93.9 ± .6}   \n",
       "Other                 Landmasses $\\S{2}$                            84.6 ± .8   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                    76.6 ± 1.6   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                    60.6 ± 1.1   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                       35.7 ± 1.4   \n",
       "                                 $\\E{4}$                  \\textbf{37.2 ± 1.8}   \n",
       "                                 $\\H{2}\\E{2}$                      39.1 ± 1.8   \n",
       "                                 $\\H{2}\\S{2}$                      37.1 ± 1.9   \n",
       "                                 $\\H{4}$                           41.4 ± 1.5   \n",
       "                                 $\\S{2}\\E{2}$             \\textbf{37.3 ± 1.4}   \n",
       "                                 $\\S{4}$                           25.8 ± 1.0   \n",
       "                                 ($\\H{2})^2$                       38.7 ± 1.2   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$  \\underline{18.3 ± .7}   \n",
       "                      CIFAR-100  $(\\S{2})^4$               \\textbf{10.6 ± .6}   \n",
       "                      Lymphoma   $(\\S{2})^2$                       82.1 ± 1.2   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$        \\textbf{38.8 ± 3.2}   \n",
       "\n",
       "                                                                  knn_accuracy  \\\n",
       "table                 dataset    signature                                       \n",
       "Graphs                CiteSeer   $\\H{4}$                             25.1 ± .5   \n",
       "                      Cora       $\\H{4}$                             20.8 ± .4   \n",
       "                      PolBlogs   $\\H{4}$                             92.9 ± .4   \n",
       "Other                 Landmasses $\\S{2}$                    \\textbf{91.8 ± .6}   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                     50.8 ± 1.6   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                     49.0 ± 1.5   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$            \\underline{36.6 ± 1.6}   \n",
       "                                 $\\E{4}$                            36.6 ± 1.3   \n",
       "                                 $\\H{2}\\E{2}$           \\underline{39.8 ± 2.3}   \n",
       "                                 $\\H{2}\\S{2}$              \\textbf{38.1 ± 2.5}   \n",
       "                                 $\\H{4}$                   \\textbf{45.3 ± 1.6}   \n",
       "                                 $\\S{2}\\E{2}$                       35.9 ± 1.3   \n",
       "                                 $\\S{4}$                    \\textbf{30.2 ± .8}   \n",
       "                                 ($\\H{2})^2$               \\textbf{40.5 ± 1.0}   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$               15.9 ± .6   \n",
       "                      CIFAR-100  $(\\S{2})^4$                          7.9 ± .5   \n",
       "                      Lymphoma   $(\\S{2})^2$                        78.5 ± 1.3   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$                  35.0 ± 4.3   \n",
       "\n",
       "                                                       ps_perceptron_accuracy  \\\n",
       "table                 dataset    signature                                      \n",
       "Graphs                CiteSeer   $\\H{4}$                            14.0 ± .4   \n",
       "                      Cora       $\\H{4}$                            16.4 ± .4   \n",
       "                      PolBlogs   $\\H{4}$                            48.2 ± .7   \n",
       "Other                 Landmasses $\\S{2}$                           69.8 ± 1.0   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                     54.7 ± .9   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                    51.9 ± 1.0   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                       25.1 ± 1.6   \n",
       "                                 $\\E{4}$                           24.0 ± 2.6   \n",
       "                                 $\\H{2}\\E{2}$                      20.7 ± 2.5   \n",
       "                                 $\\H{2}\\S{2}$                      20.2 ± 1.8   \n",
       "                                 $\\H{4}$                           18.9 ± 2.6   \n",
       "                                 $\\S{2}\\E{2}$                      25.8 ± 2.1   \n",
       "                                 $\\S{4}$                            15.4 ± .8   \n",
       "                                 ($\\H{2})^2$                        15.8 ± .9   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$               2.6 ± .2   \n",
       "                      CIFAR-100  $(\\S{2})^4$                         5.5 ± .3   \n",
       "                      Lymphoma   $(\\S{2})^2$                       75.7 ± 2.6   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$                 16.2 ± 3.4   \n",
       "\n",
       "                                                       ambient_mlp_accuracy  \\\n",
       "table                 dataset    signature                                    \n",
       "Graphs                CiteSeer   $\\H{4}$                          24.5 ± .7   \n",
       "                      Cora       $\\H{4}$                 \\textbf{29.9 ± .5}   \n",
       "                      PolBlogs   $\\H{4}$                          91.7 ± .4   \n",
       "Other                 Landmasses $\\S{2}$                          69.9 ± .8   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                  46.1 ± 1.4   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                  48.1 ± 1.1   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                     30.5 ± 1.4   \n",
       "                                 $\\E{4}$                         30.6 ± 1.5   \n",
       "                                 $\\H{2}\\E{2}$                    32.2 ± 2.0   \n",
       "                                 $\\H{2}\\S{2}$                    32.0 ± 1.7   \n",
       "                                 $\\H{4}$                         33.5 ± 2.1   \n",
       "                                 $\\S{2}\\E{2}$                    29.7 ± 1.1   \n",
       "                                 $\\S{4}$                         19.9 ± 1.2   \n",
       "                                 ($\\H{2})^2$                     31.5 ± 1.9   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$            12.0 ± .4   \n",
       "                      CIFAR-100  $(\\S{2})^4$                       8.1 ± .4   \n",
       "                      Lymphoma   $(\\S{2})^2$                      78.4 ± .3   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$               35.2 ± 3.9   \n",
       "\n",
       "                                                       ambient_gnn_accuracy  \\\n",
       "table                 dataset    signature                                    \n",
       "Graphs                CiteSeer   $\\H{4}$                          24.3 ± .6   \n",
       "                      Cora       $\\H{4}$                          29.6 ± .5   \n",
       "                      PolBlogs   $\\H{4}$                          92.2 ± .4   \n",
       "Other                 Landmasses $\\S{2}$                          77.2 ± .7   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                  48.1 ± 1.6   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                  48.3 ± 1.0   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                     24.7 ± 1.2   \n",
       "                                 $\\E{4}$                         26.8 ± 2.1   \n",
       "                                 $\\H{2}\\E{2}$                    27.8 ± 1.5   \n",
       "                                 $\\H{2}\\S{2}$                    22.5 ± 1.3   \n",
       "                                 $\\H{4}$                         18.0 ± 2.8   \n",
       "                                 $\\S{2}\\E{2}$                    26.7 ± 1.2   \n",
       "                                 $\\S{4}$                         21.1 ± 1.5   \n",
       "                                 ($\\H{2})^2$                     22.5 ± 1.1   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$            12.0 ± .4   \n",
       "                      CIFAR-100  $(\\S{2})^4$                       5.5 ± .3   \n",
       "                      Lymphoma   $(\\S{2})^2$                      78.4 ± .3   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$               14.7 ± 1.7   \n",
       "\n",
       "                                                       kappa_gcn_accuracy  \\\n",
       "table                 dataset    signature                                  \n",
       "Graphs                CiteSeer   $\\H{4}$                        23.8 ± .5   \n",
       "                      Cora       $\\H{4}$                        29.7 ± .5   \n",
       "                      PolBlogs   $\\H{4}$                        91.5 ± .7   \n",
       "Other                 Landmasses $\\S{2}$                       71.4 ± 1.7   \n",
       "                      Neuron 33  $(\\S{1})^{10}$                48.9 ± 1.8   \n",
       "                      Neuron 46  $(\\S{1})^{10}$                48.0 ± 1.0   \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                   14.4 ± 2.5   \n",
       "                                 $\\E{4}$                       26.3 ± 2.3   \n",
       "                                 $\\H{2}\\E{2}$                  25.2 ± 1.6   \n",
       "                                 $\\H{2}\\S{2}$                  14.8 ± 2.4   \n",
       "                                 $\\H{4}$                       25.0 ± 2.6   \n",
       "                                 $\\S{2}\\E{2}$                  22.0 ± 2.5   \n",
       "                                 $\\S{4}$                        17.4 ± .5   \n",
       "                                 ($\\H{2})^2$                   24.3 ± 1.7   \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$          11.3 ± .4   \n",
       "                      CIFAR-100  $(\\S{2})^4$                     4.9 ± .3   \n",
       "                      Lymphoma   $(\\S{2})^2$                   73.0 ± 5.6   \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$             11.3 ± 1.1   \n",
       "\n",
       "                                                         product_mlr_accuracy  \n",
       "table                 dataset    signature                                     \n",
       "Graphs                CiteSeer   $\\H{4}$                            25.2 ± .7  \n",
       "                      Cora       $\\H{4}$                \\underline{29.8 ± .4}  \n",
       "                      PolBlogs   $\\H{4}$                           89.8 ± 1.0  \n",
       "Other                 Landmasses $\\S{2}$                            65.2 ± .9  \n",
       "                      Neuron 33  $(\\S{1})^{10}$                    47.7 ± 1.4  \n",
       "                      Neuron 46  $(\\S{1})^{10}$                    47.8 ± 1.4  \n",
       "Synthetic (multi-$K$) Gaussian   $(\\S{2})^2$                       13.4 ± 2.4  \n",
       "                                 $\\E{4}$                           30.6 ± 1.4  \n",
       "                                 $\\H{2}\\E{2}$                      31.4 ± 2.3  \n",
       "                                 $\\H{2}\\S{2}$                      17.7 ± 2.9  \n",
       "                                 $\\H{4}$                           34.5 ± 2.2  \n",
       "                                 $\\S{2}\\E{2}$                      17.5 ± 2.4  \n",
       "                                 $\\S{4}$                           16.5 ± 1.5  \n",
       "                                 ($\\H{2})^2$                       29.8 ± 1.8  \n",
       "VAE                   Blood      $\\S{2}\\E{2}(\\H{2})^3$              11.2 ± .3  \n",
       "                      CIFAR-100  $(\\S{2})^4$                         5.4 ± .4  \n",
       "                      Lymphoma   $(\\S{2})^2$                       67.2 ± 7.6  \n",
       "                      MNIST      $\\S{2}\\E{2}\\H{2}$                 21.8 ± 3.1  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to format a LaTeX cell with mean ± SE and symbols\n",
    "def format_latex_cell(mean, se, bold=False, underline=False, regression=False):\n",
    "    if regression:\n",
    "        formatted = f\"{mean:.3f}\".lstrip(\"0\") + \" ± \" + f\"{se:.3f}\".lstrip(\"0\")\n",
    "    else:\n",
    "        formatted = f\"{mean * 100:.1f}\".lstrip(\"0\") + \" ± \" + f\"{se * 100:.1f}\".lstrip(\"0\")\n",
    "    if bold:\n",
    "        formatted = f\"\\\\textbf{{{formatted}}}\"\n",
    "    if underline:\n",
    "        formatted = f\"\\\\underline{{{formatted}}}\"\n",
    "    return formatted\n",
    "\n",
    "\n",
    "def agg(x, regression=False):\n",
    "    # Mean and standard error\n",
    "    decimals = 3\n",
    "    mean = x.mean().round(decimals)\n",
    "    sem = x.sem().round(decimals)\n",
    "\n",
    "    # Underlines\n",
    "    if regression:\n",
    "        top1, top2 = mean.drop_duplicates().nsmallest(2)\n",
    "    else:\n",
    "        top1, top2 = mean.drop_duplicates().nlargest(2)\n",
    "    bold = mean == top1\n",
    "    if sum(bold) > 1:\n",
    "        underline = [False] * len(bold)\n",
    "    else:\n",
    "        underline = mean == top2\n",
    "\n",
    "    out = pd.Series(\n",
    "        [\n",
    "            format_latex_cell(m, s, bold=b, underline=u, regression=regression)\n",
    "            for m, s, b, u in zip(mean, sem, bold, underline)\n",
    "        ]\n",
    "    )\n",
    "    out.index = mean.index\n",
    "    return out\n",
    "\n",
    "\n",
    "all_c_grouped = all_c.groupby([\"table\", \"dataset\", \"signature\"])[\n",
    "    [c for c in all_c_grouped.columns if \"accuracy\" in c]\n",
    "].apply(lambda x: agg(x))\n",
    "\n",
    "all_c_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort \"table\" in MultiIndex: Synthetic, Graph, VAE, Other\n",
    "sort_order = [\"Synthetic (multi-$K$)\", \"Graphs\", \"VAE\", \"Other\"]\n",
    "sort_dict = {name: i for i, name in enumerate(sort_order)}\n",
    "all_c_grouped = all_c_grouped.sort_index(level=\"table\", key=lambda x: x.map(sort_dict))\n",
    "\n",
    "# Get the columns fixed up\n",
    "latex_df = all_c_grouped[\n",
    "    [\n",
    "        \"product_rf_accuracy\",\n",
    "        \"sklearn_rf_accuracy\",\n",
    "        \"tangent_rf_accuracy\",\n",
    "        \"knn_accuracy\",\n",
    "        \"ambient_mlp_accuracy\",\n",
    "        \"kappa_gcn_accuracy\",\n",
    "    ]\n",
    "]\n",
    "c_dict = {\n",
    "    # \"Synthetic (single $K$)\": \"-5.5cm\",\n",
    "    \"Synthetic (multi-$K$)\": \"-2.4cm\",\n",
    "    \"Graphs\": \"-.8cm\",\n",
    "    \"VAE\": \"-.8cm\",\n",
    "    \"Other\": \"-.7cm\",\n",
    "}\n",
    "latex_df.index = pd.MultiIndex.from_tuples(\n",
    "    [(f\"\\\\rotatebox{{90}}{{\\\\hspace{{{c_dict[c]}}}{c}}}\", d, s) for c, d, s in latex_df.index],\n",
    "    names=[\"\", \"Dataset\", \"Signature\"],\n",
    ")\n",
    "\n",
    "# Now we do text manipulation\n",
    "latex = latex_df.to_latex(header=True, escape=False)\n",
    "\n",
    "# Remove all occurrences of \"\\cline{3-9}\"\n",
    "# latex = latex.replace(\"\\\\cline{1-9}\", \"\")\n",
    "latex = latex.replace(\"\\\\cline{2-9}\", \"\")\n",
    "\n",
    "# Change top bar\n",
    "my_toprule = \"\"\"\\\\toprule\n",
    "& Dataset & Signature & \\col{product_dt}{Product RF} & \\col{euclidean_dt}{Ambient RF} & \\col{tangent_dt}{Tangent RF} \n",
    "& \\col{knn}{$k$-Neighbors} & \\col{mlp}{MLP} & \\col{kgcn}{$\\kappa$-GCN} \\\\\\\\\n",
    "\\midrule\"\"\"\n",
    "latex = latex.split(\"\\n\")\n",
    "latex = [latex[0], my_toprule] + latex[5:-4] + latex[-3:]\n",
    "latex = \"\\n\".join(latex)\n",
    "\n",
    "with open(\"../data/results_icml/table2.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "_t1, _t2 = pd.Series([1, 2, 3, 4, 5, 5, 5.0001]).round(1).drop_duplicates().nlargest(2)\n",
    "print(_t1)\n",
    "print(_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r = pd.concat([reg_sig, graphs_r, empirical_r])\n",
    "all_r = all_r.drop(columns=[\"embedding\", \"seed\", \"trial\", \"task\"])\n",
    "\n",
    "all_r_grouped = all_r.groupby([\"table\", \"dataset\", \"signature\"])[[c for c in all_r.columns if \"rmse\" in c]].apply(\n",
    "    lambda x: agg(x, regression=True)\n",
    ")\n",
    "\n",
    "# Sort \"table\" in MultiIndex: Synthetic, Graph, VAE, Other\n",
    "all_r_grouped = all_r_grouped.sort_index(level=\"table\", key=lambda x: x.map(sort_dict))\n",
    "\n",
    "# Get the columns fixed up\n",
    "latex_df = all_r_grouped[\n",
    "    [\n",
    "        \"product_rf_rmse\",\n",
    "        \"sklearn_rf_rmse\",\n",
    "        \"tangent_rf_rmse\",\n",
    "        \"knn_rmse\",\n",
    "        # \"ambient_mlp_rmse\",\n",
    "        # \"kappa_gcn_rmse\"\n",
    "    ]\n",
    "]\n",
    "c_dict = {\n",
    "    # \"Synthetic (single $K$)\": \"-5.5cm\",\n",
    "    \"Synthetic (multi-$K$)\": \"-2.4cm\",\n",
    "    \"Graphs\": \"-.7cm\",\n",
    "    # \"VAE\": \"-.8cm\",\n",
    "    \"Other\": \"-.7cm\",\n",
    "}\n",
    "latex_df.index = pd.MultiIndex.from_tuples(\n",
    "    [(f\"\\\\rotatebox{{90}}{{\\\\hspace{{{c_dict[c]}}}{c}}}\", d, s) for c, d, s in latex_df.index],\n",
    "    names=[\"\", \"Dataset\", \"Signature\"],\n",
    ")\n",
    "\n",
    "# Now we do text manipulation\n",
    "latex = latex_df.to_latex(header=True, escape=False)\n",
    "\n",
    "# Remove all occurrences of \"\\cline{3-9}\"\n",
    "latex = latex.replace(\"\\\\cline{1-9}\", \"\")\n",
    "# latex = latex.replace(\"\\\\cline{2-9}\", \"\")\n",
    "\n",
    "# Change top bar\n",
    "my_toprule = \"\"\"\\\\toprule\n",
    "& Dataset & Signature & \\col{product_dt}{Product RF} & \\col{euclidean_dt}{Ambient RF} & \\col{tangent_dt}{Tangent RF} \n",
    "& \\col{knn}{$k$-Neighbors}\\\\\\\\\n",
    "\\midrule\"\"\"\n",
    "latex = latex.split(\"\\n\")\n",
    "latex = [latex[0], my_toprule] + latex[5:-4] + latex[-3:]\n",
    "latex = \"\\n\".join(latex)\n",
    "\n",
    "with open(\"../data/results_icml/table3.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lp = pd.concat([links])\n",
    "all_lp = all_lp.drop(columns=[\"d_avg\", \"task\", \"signature\"])\n",
    "\n",
    "all_lp_grouped = all_lp.groupby([\"dataset\"])[[c for c in all_lp.columns if \"accuracy\" in c]].apply(lambda x: agg(x))\n",
    "\n",
    "# Sort \"table\" in MultiIndex: Synthetic, Graph, VAE, Other\n",
    "# all_lp_grouped = all_lp_grouped.sort_index(level=\"table\", key=lambda x: x.map(sort_dict))\n",
    "\n",
    "# Get the columns fixed up\n",
    "latex_df = all_lp_grouped[\n",
    "    [\n",
    "        # \"product_dt_accuracy\",\n",
    "        \"product_rf_accuracy\",\n",
    "        # \"sklearn_dt_accuracy\",\n",
    "        \"sklearn_rf_accuracy\",\n",
    "        # \"tangent_dt_accuracy\",\n",
    "        \"tangent_rf_accuracy\",\n",
    "        \"knn_accuracy\",\n",
    "        \"ambient_mlp_accuracy\",\n",
    "        \"kappa_gcn_accuracy\",\n",
    "    ]\n",
    "]\n",
    "# c_dict = {\n",
    "#     # \"Synthetic (single $K$)\": \"-5.5cm\",\n",
    "#     \"Synthetic (multi-$K$)\": \"-2.4cm\",\n",
    "#     \"Graphs\": \"-.8cm\",\n",
    "#     \"VAE\": \"-.8cm\",\n",
    "#     \"Other\": \"-1cm\",\n",
    "# }\n",
    "# latex_df.index = pd.MultiIndex.from_tuples(\n",
    "#     [(f\"\\\\rotatebox{{90}}{{\\\\hspace{{{c_dict[c]}}}{c}}}\", d, s) for c, d, s in latex_df.index],\n",
    "#     names=[\"\", \"Dataset\", \"Signature\"],\n",
    "# )\n",
    "latex_df\n",
    "\n",
    "# Now we do text manipulation\n",
    "latex = latex_df.to_latex(header=True, escape=False)\n",
    "\n",
    "# Remove all occurrences of \"\\cline{3-9}\"\n",
    "latex = latex.replace(\"\\\\cline{1-9}\", \"\")\n",
    "# latex = latex.replace(\"\\\\cline{2-9}\", \"\")\n",
    "\n",
    "# Change top bar\n",
    "my_toprule = \"\"\"\\\\toprule\n",
    "Dataset & \\col{product_dt}{Product RF} & \\col{euclidean_dt}{Ambient RF} & \\col{tangent_dt}{Tangent RF} \n",
    "& \\col{knn}{$k$-Neighbors} & \\col{mlp}{MLP} & \\col{kgcn}{$\\kappa$-GCN}\\\\\\\\\n",
    "\\midrule\"\"\"\n",
    "latex = latex.split(\"\\n\")\n",
    "latex = [latex[0], my_toprule] + latex[5:-4] + latex[-3:]\n",
    "latex = \"\\n\".join(latex)\n",
    "\n",
    "with open(\"../data/results_icml/table4.tex\", \"w\") as f:\n",
    "    f.write(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
